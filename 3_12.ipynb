{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAIBwP7X66p/L/NILfcASW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annie00000/Project/blob/main/3_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 一."
      ],
      "metadata": {
        "id": "TcXHJKapzTaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataGenerator(Sequence): # 定義一個自定義的數據生成器類別，繼承自Sequence，以支援多線程處理和確保數據按順序生成。\n",
        "    def __init__(self, image_paths, labels, batch_size=16, target_size=(224,224), label_to_index, num_classes, shuffle=True):\n",
        "        self.image_paths = np.array(image_paths) # 將圖像路徑列表轉換為numpy數組，用於高效訪問。\n",
        "        self.labels = np.array(labels) # 將標籤列表轉換為numpy數組。\n",
        "        self.batch_size = batch_size # 設定每個批次的大小。\n",
        "        self.target_size = target_size # 圖像將被調整的目標大小。\n",
        "        self.augmentation = augmentation # 數據增強函數，用於在加載圖像時應用。\n",
        "        self.label_to_index = label_to_index # 將標籤轉換為索引的映射。\n",
        "        self.num_classes = num_classes # 數據集中的類別總數。\n",
        "        self.shuffle = shuffle # 是否在每個epoch開始時隨機打亂數據。\n",
        "        self.on_epoch_end() # 在初始化時調用此方法，用於準備數據。\n",
        "\n",
        "    def __len__(self): # 計算並返回總批次數，確保即使最後一個批次不滿也能被處理。\n",
        "        return int(np.ceil(len(self.image_paths) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx): # 根據當前索引計算該批次應該加載的圖像的索引。\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_images = [] # 初始化批次圖像列表。\n",
        "        batch_labels = [] # 初始化批次標籤列表。\n",
        "\n",
        "        for i in batch_indices: # 遍歷批次中的每一個索引。\n",
        "            img_path = self.image_paths[i] # 獲取對應的圖像路徑。\n",
        "            label = self.labels[i] # 獲取對應的標籤。\n",
        "\n",
        "            # 加載和預處理圖像\n",
        "            img = tf.io.read_file(img_path) # 讀取圖像文件。\n",
        "            img = tf.image.decode_image(img, channels=3) # 解碼圖像，指定使用3個顏色通道。\n",
        "            img = tf.image.resize(img, self.target_size)/255 # 調整圖像大小並進行歸一化。\n",
        "\n",
        "            # 應用數據增強（如果有指定）\n",
        "            if self.augmentation:\n",
        "                img = self.augmentation(img) # 應用增強函數。\n",
        "\n",
        "            batch_images.append(img) # 添加處理後的圖像到批次列表。\n",
        "            batch_labels.append(self.label_to_index[label]) # 將標籤轉換為索引並添加到批次標籤列表。\n",
        "\n",
        "        # 返回處理後的批次圖像和標籤。\n",
        "        return tf.convert_to_tensor(batch_images), tf.keras.utils.to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.image_paths)) # 創建一個從0到圖像路徑數組長度的索引數組。\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices) # 如果shuffle為True，則隨機打亂索引數組。\n"
      ],
      "metadata": {
        "id": "bbVMQUJ3yFLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1)"
      ],
      "metadata": {
        "id": "wCHnWrG21R9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "這段程式碼是一個自定義的數據生成器，用於機器學習訓練過程中動態地從硬碟讀取數據。我將逐行解釋其功能：\n",
        "\n",
        "1. **定義一個類別 `CustomDataGenerator`，繼承自 `Sequence`**：這意味著這個類別可以安全地用於多線程環境，並且提供了一個接口來遍歷數據。\n",
        "\n",
        "2. **`__init__` 方法定義**：這是一個構造器，用於初始化類的實例。它接收多個參數，包括圖片路徑、標籤、批次大小、目標大小、數據增強函數、標籤到索引的映射、類別數量以及是否在每個時代結束時打亂數據。\n",
        "\n",
        "    - `self.image_paths`：儲存圖片路徑的數組。\n",
        "    - `self.labels`：儲存圖片對應標籤的數組。\n",
        "    - `self.batch_size`：每次生成的批量大小。\n",
        "    - `self.target_size`：將圖片調整到的目標大小。\n",
        "    - `self.augmentation`：數據增強方法。\n",
        "    - `self.label_to_index`：將標籤映射到索引的字典。\n",
        "    - `self.num_classes`：數據集中總類別數。\n",
        "    - `self.shuffle`：是否在每個epoch結束時打亂數據。\n",
        "    - `self.on_epoch_end()`：初始化時調用此方法來準備數據。\n",
        "\n",
        "3. **`__len__` 方法定義**：返回整個數據集中批次的總數量，用於 `fit` 方法知道每個時代需要迭代多少次。\n",
        "\n",
        "4. **`__getitem__` 方法定義**：根據索引 `idx`，生成並返回一個批次的數據。這包括加載圖像、應用預處理、進行數據增強和轉換標籤。\n",
        "\n",
        "    - 加載圖像：從硬碟讀取圖像，解碼，調整大小，並進行歸一化。\n",
        "    - 數據增強：根據 `self.augmentation` 指定的方法，對圖像進行增強。\n",
        "    - 轉換標籤：將標籤從文本轉換為索引，並使用 `to_categorical` 方法轉換為獨熱編碼。\n",
        "\n",
        "5. **`on_epoch_end` 方法定義**：每當一個時代結束時被調用，用於重新生成索引數組。如果設定為打亂，則對索引進行打亂，以確保下一個時代的數據順序不同。\n",
        "\n",
        "整體來看，這段程式碼允許以高效和靈活的方式從硬碟動態加載和處理圖像數據，適用於大規模數據集的深度學習訓練。"
      ],
      "metadata": {
        "id": "9x9JkxCUxnNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2)"
      ],
      "metadata": {
        "id": "ZUBidOz31TXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码定义了一个名为`CustomDataGenerator`的类，用于在机器学习训练中生成图像数据批次。这个类继承自`Sequence`，使得它可以被Keras在训练时用作数据生成器。下面是对每一行代码的功能解释：\n",
        "\n",
        "1. `class CustomDataGenerator(Sequence):` 定义了一个名为`CustomDataGenerator`的类，该类继承自`Sequence`。`Sequence`是Keras的一个基类，用于数据生成器的顺序访问。\n",
        "\n",
        "2. `def __init__(self, image_paths, labels, batch_size=16, target_size=(224,224), label_to_index, num_classes, shuffle=True):` 这是类的初始化函数，它接受多个参数：\n",
        "   - `image_paths`: 图像文件的路径列表。\n",
        "   - `labels`: 与图像对应的标签列表。\n",
        "   - `batch_size=16`: 每个批次的图像数量，默认值为16。\n",
        "   - `target_size=(224,224)`: 图像将被调整的目标大小，默认为224x224像素。\n",
        "   - `label_to_index`: 将标签映射到索引的字典。\n",
        "   - `num_classes`: 类别总数。\n",
        "   - `shuffle=True`: 是否在每个时代结束时随机打乱数据，默认为True。\n",
        "\n",
        "3. `self.image_paths = np.array(image_paths)`：将传入的图像路径列表转换为Numpy数组，便于后续操作。\n",
        "\n",
        "4. `self.labels = np.array(labels)`：将传入的标签列表转换为Numpy数组。\n",
        "\n",
        "5. 后续几行代码，将其他传入的参数分别赋值给类的内部变量。\n",
        "\n",
        "6. `self.on_epoch_end()`：在初始化函数的最后调用`on_epoch_end`方法，用于初始化数据生成器的状态，包括可选的打乱数据。\n",
        "\n",
        "7. `def __len__(self):` 定义了一个特殊方法，返回在遍历完所有数据前，生成器能生成的批次总数。\n",
        "\n",
        "8. `def __getitem__(self, idx):` 定义了一个特殊方法，用于获取第`idx`个批次的数据。这个方法首先计算当前批次的索引，然后加载和预处理这些索引对应的图像和标签。\n",
        "\n",
        "9. 图像加载和预处理的代码块：\n",
        "   - 通过`tf.io.read_file`读取图像文件，\n",
        "   - 用`tf.image.decode_image`解码图像，\n",
        "   - 通过`tf.image.resize`调整图像大小，\n",
        "   - 最后，图像像素值被归一化到0到1之间。\n",
        "\n",
        "10. 如果启用了数据增强(`self.augmentation`)，应用数据增强操作。例如，使用随机旋转。\n",
        "\n",
        "11. 将处理后的图像和经过映射的标签分别追加到`batch_images`和`batch_labels`列表中。\n",
        "\n",
        "12. 返回转换为张量的图像批次和使用`to_categorical`函数转换的独热编码标签批次。\n",
        "\n",
        "13. `def on_epoch_end(self):` 定义了一个方法，用于在每个时代结束时重新初始化数据生成器的状态。这包括重新生成索引数组并根据`self.shuffle`决定是否打乱索引。\n",
        "\n",
        "整体来说，这个类提供了一种灵活的方式来生成经过预处理和可选的数据增强的图像数据批次，非常适合用于训练机器学习模型。"
      ],
      "metadata": {
        "id": "QoEfU6X61TRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3)"
      ],
      "metadata": {
        "id": "Mj3idaVa1PWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.image.decode_image` 和图像解码，以及 `resize` 和除以 `255` 的操作，都是图像预处理流程的关键步骤，特别是在准备数据用于深度学习模型时。我将分别解释它们的作用：\n",
        "\n",
        "### `tf.image.decode_image`\n",
        "- **作用**：这个函数用于将编码的图像文件（如JPEG、PNG、GIF等格式）读入并转换成TensorFlow可以操作的张量（Tensor）格式。简而言之，它把图像文件的原始字节转换成了一个数值化的张量形式，这个张量可以被用于后续的图像处理操作和模型训练。\n",
        "- **为何要解码**：图像文件在存储和传输时通常是压缩和编码的，以减少文件大小。然而，为了进行图像处理和模型训练，需要将这些文件转换为一种数值表示，即解码过程。解码是从原始文件格式到可以进行数学和逻辑操作的数值张量的转换。\n",
        "\n",
        "### `resize`\n",
        "- **作用**：`resize` 函数将图像的大小调整到指定的尺寸。这通常是因为深度学习模型要求输入的图像具有统一的尺寸，这样模型才能正确地处理它们。调整图像大小是确保所有输入数据都符合模型要求的标准步骤。\n",
        "- **重要性**：在许多深度学习应用中，尤其是在使用卷积神经网络（CNNs）时，输入图像的尺寸需要标准化，因为网络的第一层期望的输入维度是固定的。\n",
        "\n",
        "### `/255`\n",
        "- **作用**：这个操作将图像的像素值（通常在0到255之间）缩放到0到1之间。这是一种称为归一化的处理方式，目的是将输入数据的范围缩放到模型工作的最佳数值范围内。\n",
        "- **为什么要归一化**：归一化有助于加快训练过程，提高模型在训练过程中的稳定性和收敛速度。当输入特征具有相似的范围时，梯度下降法（用于训练神经网络的常见算法）会更加有效，因为它可以防止某些特征在优化过程中占据主导地位。\n",
        "\n",
        "总之，`tf.image.decode_image` 用于将图像文件转换为可操作的数值张量，`resize` 确保所有图像都符合模型所需的尺寸，而除以 `255` 是将像素值归一化，以便于模型的训练和泛化。这些步骤共同构成了图像预处理的标准流程，对于实现高效且准确的模型训练至关重要。"
      ],
      "metadata": {
        "id": "CBdS18NWzQSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`__len__` 方法在Python中定义了一个对象的“长度”。对于不同类型的对象，长度有不同的含义。例如，对于一个列表，长度是它包含的元素数量；对于一个字符串，长度是字符的数量。当你使用 `len()` 函数时，Python内部会调用对象的 `__len__` 方法来获取其长度。\n",
        "\n",
        "在 `CustomDataGenerator` 类的上下文中，`__len__` 方法用于表示数据生成器可以生成的批次总数。这对于使用Keras（或其他支持此机制的框架）进行模型训练时非常重要，因为它告诉训练过程，每个epoch（训练周期）中有多少批数据需要处理。\n",
        "\n",
        "具体来说，`CustomDataGenerator` 类的 `__len__` 方法通过以下代码实现：\n",
        "\n",
        "```python\n",
        "def __len__(self):\n",
        "    return int(np.ceil(len(self.image_paths) / float(self.batch_size)))\n",
        "```\n",
        "\n",
        "这里，`len(self.image_paths)` 表示总的图像数量，`self.batch_size` 是每个批次包含的图像数量。`np.ceil` 函数将除法的结果向上圆整到最接近的整数，以确保即使最后一个批次不完整（即图像数量不足以形成一个完整的批次）也能被处理。这样，`__len__` 方法的返回值就是整个数据集被完全遍历一次所需要的批次数量。\n",
        "\n",
        "在实际使用中，如果你创建了一个`CustomDataGenerator`的实例：\n",
        "\n",
        "```python\n",
        "data_generator = CustomDataGenerator(image_paths=my_image_paths, labels=my_labels, batch_size=16)\n",
        "```\n",
        "\n",
        "然后，你可以使用`len()`函数来获取可以从这个生成器中生成的批次总数：\n",
        "\n",
        "```python\n",
        "total_batches = len(data_generator)\n",
        "```\n",
        "\n",
        "这在配置训练循环时非常有用，因为你需要知道每个epoch中有多少批数据需要处理。"
      ],
      "metadata": {
        "id": "DN5TaiIk1gvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 二."
      ],
      "metadata": {
        "id": "AlJTfkRrzWV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "nrv5-FJWxoUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码使用TensorFlow库来管理GPU资源，特别是针对GPU内存的使用。让我们逐步解释每一部分的功能：\n",
        "\n",
        "1. `gpus = tf.config.list_physical_devices('GPU')`：这行代码调用TensorFlow的`tf.config.list_physical_devices`函数，传入参数`'GPU'`来获取系统中所有可用的物理GPU设备列表，并将这个列表赋值给变量`gpus`。\n",
        "\n",
        "2. `if gpus:`：这行代码检查`gpus`列表是否不为空。如果系统中至少有一个GPU，那么`gpus`列表中会有元素，条件判断为真，执行下面的代码块。\n",
        "\n",
        "3. `try:`：这是一个`try`语句，用来尝试执行一段代码，并允许我们通过`except`子句来捕捉特定类型的异常。这里的目的是尝试配置GPU的内存增长。\n",
        "\n",
        "4. `for gpu in gpus:`：这是一个循环，遍历`gpus`列表中的每个GPU设备。\n",
        "\n",
        "5. `tf.config.experimental.set_memory_growth(gpu, True)`：对于每个GPU，这行代码调用`tf.config.experimental.set_memory_growth`函数，为该GPU启用内存增长。将第二个参数设置为`True`意味着TensorFlow不会一次性占用所有可用的GPU内存，而是根据需要动态增加内存使用量。这有助于在多个程序之间共享GPU资源。\n",
        "\n",
        "6. `logical_gpus = tf.config.list_logical_devices('GPU')`：这行代码获取系统中所有可用的逻辑GPU设备列表，并将其赋值给变量`logical_gpus`。逻辑GPU设备可能与物理GPU设备不同，这取决于TensorFlow的配置和是否启用了如内存增长等特性。\n",
        "\n",
        "7. `print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")`：这行代码打印出物理GPU的数量和逻辑GPU的数量，用于提供GPU配置的概览。\n",
        "\n",
        "8. `except RuntimeError as e:`：这是`try`块的`except`子句，用于捕获`RuntimeError`异常。如果在GPU已经被初始化之后尝试设置内存增长，TensorFlow会抛出`RuntimeError`。这行代码的作用是在出现这种情况时捕获异常并打印出错信息。\n",
        "\n",
        "9. `print(e)`：如果捕获到`RuntimeError`，这行代码会打印出异常信息，通常是关于为什么无法设置内存增长的详细原因。\n",
        "\n",
        "总的来说，这段代码的目的是在系统中配置一个或多个GPU的内存使用方式，使其在需要时动态增长，而不是一开始就占用所有可用内存。这有助于更高效地利用有限的GPU资源，尤其是在同一台机器上运行多个GPU密集型任务时。"
      ],
      "metadata": {
        "id": "4xRlJiuG23y1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 三."
      ],
      "metadata": {
        "id": "BFQLLU_VzY1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Xception(include_top=False, input_shape=(224, 224, 3), weights='imagenet'),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256,activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(len(unique_labels), activation='softmax')\n",
        "])\n",
        "\n",
        "# 編譯模型\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "drowJI1ly35N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1)"
      ],
      "metadata": {
        "id": "SRYAcqkK0GEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码涉及两个主要部分：创建一个基于Xception架构的深度学习模型，并编译这个模型以供训练。我将解释每一行的作用：\n",
        "\n",
        "实际上，这里创建的是一个基于Xception架构的模型，而不是DenseNet。代码使用了Keras的`Sequential`模型框架来顺序堆叠不同的层。\n",
        "\n",
        "\n",
        "\n",
        "1. **`Xception(include_top=False, input_shape=(224, 224, 3), weights='imagenet')`**：这行代码添加了预训练的Xception模型作为Sequential模型的第一层。`include_top=False` 表示不包括Xception模型顶部的全连接层，允许我们为模型添加自定义的分类层。`input_shape=(224, 224, 3)` 指定输入图像的形状为224x224像素，且有3个颜色通道（RGB）。`weights='imagenet'` 使用在ImageNet数据集上预训练的权重来初始化模型，这有助于模型更好地学习和泛化。\n",
        "\n",
        "2. **`GlobalAveragePooling2D()`**：对前一层的特征图进行全局平均池化。这减少了模型的参数数量，并减少了过拟合的风险。\n",
        "\n",
        "3. **`Dense(256,activation='relu')`**：添加一个有256个神经元的全连接层，激活函数为ReLU。这一层的目的是从池化后的特征中学习更高级的特征表示。\n",
        "\n",
        "4. **`Dropout(0.4)`**：添加了一个Dropout层，以0.4的比率随机断开输入神经元的连接，以减少过拟合。这有助于模型学习更加鲁棒的特征表示。\n",
        "\n",
        "5. **`Dense(len(unique_labels), activation='softmax')`**：最后一层是一个全连接层，神经元的数量等于类别的数量。激活函数为softmax，用于输出每个类别的预测概率。这样，模型可以进行多分类。\n",
        "\n",
        "### 编译模型\n",
        "\n",
        "```python\n",
        "# 編譯模型\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "- **`optimizer='adam'`**：选择Adam优化器用于训练模型。Adam是一种效率较高的随机梯度下降变体，它通常在许多不同类型的深度学习模型中表现良好。\n",
        "\n",
        "- **`loss='categorical_crossentropy'`**：由于这是一个多分类问题，使用类别交叉熵作为损失函数。这个函数测量真实标签和预测标签之间的差异，目标是在训练过程中最小化这一差异。\n",
        "\n",
        "- **`metrics=['accuracy']`**：在训练和测试模型时，追踪准确率作为性能的指标。准确率衡量的是模型正确分类的样本比例。\n",
        "\n",
        "综上所述，这段代码定义并编译了一个利用预训练的Xception模型的深度学习网络，通过添加自定义层来进行多分类任务，并使用Adam优化器和类别交叉熵损失函数来进行训练。"
      ],
      "metadata": {
        "id": "t7zmC2Efz2Kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2)"
      ],
      "metadata": {
        "id": "7g2jl__w0JCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码展示了如何使用 Keras （一个高级神经网络 API，TensorFlow 的一部分）来构建和编译一个深度学习模型，具体用到了 Xception 预训练模型。我将逐行解释代码的功能：\n",
        "\n",
        "### 创建 DenseNet 模型\n",
        "实际上，这段代码创建的是一个基于 Xception 的模型，而非 DenseNet。可能是注释写错了。下面是针对代码的解释：\n",
        "\n",
        "1. **`Sequential`**：这一行开始构造一个 `Sequential` 模型。`Sequential` 模型是一种线性堆叠的模型，允许你将一层层模型堆叠起来。\n",
        "\n",
        "2. **`Xception(include_top=False, input_shape=(224, 224, 3), weights='imagenet')`**：将 Xception 模型作为基底模型添加到序列中。这里的参数设置为 `include_top=False` 表明不包含网络的顶层（即分类层），以便于我们添加自定义的分类层；`input_shape=(224, 224, 3)` 指定了输入图像的形状为 224x224 像素，且有 3 个颜色通道（RGB）；`weights='imagenet'` 指定使用在 ImageNet 数据集上预训练的权重，这有助于提升模型的性能。\n",
        "\n",
        "3. **`GlobalAveragePooling2D()`**：在模型中添加一个全局平均池化层。这个层会对每个特征图进行平均池化，将特征图的尺寸从 `(batch_size, rows, cols, channels)` 缩减为 `(batch_size, channels)`，这有助于减少模型参数和计算量，防止过拟合。\n",
        "\n",
        "4. **`Dense(256, activation='relu')`**：添加一个全连接层（Dense 层），其中包含 256 个神经元，使用 ReLU（Rectified Linear Unit）激活函数。这一层负责学习特征之间的非线性组合。\n",
        "\n",
        "5. **`Dropout(0.4)`**：添加一个 Dropout 层，随机地将输入单元的 40% 设置为 0，这有助于防止模型过拟合。\n",
        "\n",
        "6. **`Dense(len(unique_labels), activation='softmax')`**：添加另一个 Dense 层作为输出层，其神经元数量等于类别的数量（`len(unique_labels)`），使用 softmax 激活函数来进行多分类。\n",
        "\n",
        "### 编译模型\n",
        "1. **`model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])`**：这一行代码编译模型，为训练过程配置了优化器、损失函数和评估指标。`optimizer='adam'` 指定使用 Adam 优化器，这是一种基于梯度下降的方法，它可以自动调整学习率，以提高性能和稳定性；`loss='categorical_crossentropy'` 设置损失函数为分类交叉熵，适用于多分类问题；`metrics=['accuracy']` 指定训练和评估模型时计算准确率。\n",
        "\n",
        "这段代码总的来说是构建了一个基于 Xception 的自定义模型，适用于图像分类任务，通过预训练的模型和添加的自定义层来进行特征学习和分类。"
      ],
      "metadata": {
        "id": "5OuQ5WhA0K2w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-xxfIMmz18I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}